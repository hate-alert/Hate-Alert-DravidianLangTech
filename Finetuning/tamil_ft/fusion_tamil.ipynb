{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV from link\n",
    "def read_csv_from_link(url):\n",
    "    path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "    df = pd.read_csv(path,delimiter=\"\\t\",error_bad_lines=False, header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading All Data\n",
    "tamil_train = read_csv_from_link('https://drive.google.com/file/d/15auwrFAlq52JJ61u7eSfnhT9rZtI5sjk/view?usp=sharing')\n",
    "tamil_dev = read_csv_from_link('https://drive.google.com/file/d/1Jme-Oftjm7OgfMNLKQs1mO_cnsQmznRI/view?usp=sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "tamil_test = read_csv_from_link('https://drive.google.com/file/d/17o-spkU5JnI_18qDJXO-F_DoIG9Zzv9q/view?usp=sharing')\n",
    "malayalam_test = read_csv_from_link('https://drive.google.com/file/d/1waRFe4yTG8TMkMruICaavd9JH0xiO_rb/view?usp=sharing')\n",
    "kannada_test = read_csv_from_link('https://drive.google.com/file/d/14DQvnNZCXSgmiZxJqGtPYFdRqBH7TOSr/view?usp=sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamil Preprocess\n",
    "tamil_train = tamil_train.iloc[:, 0:2]\n",
    "tamil_train = tamil_train.rename(columns={0: \"text\", 1: \"label\"})\n",
    "\n",
    "tamil_dev = tamil_dev.iloc[:, 0:2]\n",
    "tamil_dev = tamil_dev.rename(columns={0: \"text\", 1: \"label\"})\n",
    "\n",
    "tamil_test = tamil_test.iloc[:, 0:1]\n",
    "tamil_test = tamil_test.rename(columns={0: \"text\"})\n",
    "\n",
    "# Stats\n",
    "tamil_train['label'] = pd.Categorical(tamil_train.label)\n",
    "tamil_dev['label'] = pd.Categorical(tamil_dev.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text          label\n",
      "0                  movie vara level la Erika poguthu  Not_offensive\n",
      "1  I love Ajith Kumar Vivegam movie inki mjy bht ...      not-Tamil\n",
      "2          Padam nalla comedy padama irukum polaye..  Not_offensive\n",
      "3  karthick subburaj anne .... intha padam vetri ...  Not_offensive\n",
      "4  à®•à®µà¯à®£à¯à®Ÿà®°à¯ à®¤à¯‡à®µà®°à¯.à®šà®¾à®°à¯à®ªà®¾à®• à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®± à®µà®¾à®´à¯à®¤à¯à®¤à¯à®•à¯à®•à®³à¯ ðŸ¦  Not_offensive\n"
     ]
    }
   ],
   "source": [
    "print(tamil_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mdevi                   \u001b[m  Fri Jan  8 18:44:56 2021  \u001b[1m\u001b[30m450.51.05\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-12GB\u001b[m |\u001b[31m 44'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    6\u001b[m / \u001b[33m12198\u001b[m MB | \u001b[1m\u001b[30mgdm\u001b[m/1412(\u001b[33m4M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 42'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    6\u001b[m / \u001b[33m16280\u001b[m MB | \u001b[1m\u001b[30mgdm\u001b[m/1412(\u001b[33m4M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat -p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU Nos: {}\".format(torch.cuda.device_count()))\n",
    "# print(torch.cuda.get_device_name(0))\n",
    "# print(torch.cuda.get_device_name(1))\n",
    "\n",
    "# Change Device - CPU/GPU-0/GPU-1\n",
    "torch.cuda.set_device(0)\n",
    "device = 'cuda'\n",
    "device = device if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter Path of Saved model here in torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Indic_bert_offensive_only_kannada',\n",
       " 'MURIL_cased_temp_offensive_only_kannada_weighted',\n",
       " 'XLMroberta_large_kannada_weighted',\n",
       " 'Mbert_base_cased_offensive_only_kannada',\n",
       " 'Indic_bert_collated_kannada_weighted',\n",
       " 'Indic_bert_kannada',\n",
       " 'Distilbert_m_base_cased_kannada',\n",
       " 'XLMroberta_base_kannada_weighted',\n",
       " 'MURIL_cased_temp_collated_kannada_weighted',\n",
       " 'XLMroberta_custom_pretrained_collated_kannada',\n",
       " 'MURIL_cased_temp_collated_kannada',\n",
       " 'Distilbert_m_base_cased_kannada_weighted',\n",
       " 'XLMroberta_base_offensive_only_kannada_weighted',\n",
       " 'XLMroberta_custom_pretrained_kannada_weighted',\n",
       " 'XLMroberta_large_collated_kannada_weighted',\n",
       " 'XLMroberta_base_kannada',\n",
       " 'XLMroberta_custom_pretrained_offensive_only_kannada',\n",
       " 'Indic_bert_collated_kannada',\n",
       " 'MURIL_cased_temp_kannada_weighted',\n",
       " 'XLMroberta_large_kannada',\n",
       " 'Mbert_base_cased_collated_kannada_weighted',\n",
       " 'XLMroberta_custom_pretrained_collated_kannada_weighted',\n",
       " 'XLMroberta_custom_pretrained_offensive_only_kannada_weighted',\n",
       " 'Mbert_base_cased_offensive_only_kannada_weighted',\n",
       " 'XLMroberta_large_offensive_only_kannada',\n",
       " 'MURIL_cased_temp_offensive_only_kannada',\n",
       " 'Indic_bert_kannada_weighted',\n",
       " 'MURIL_cased_temp_kannada',\n",
       " 'XLMroberta_large_offensive_only_kannada_weighted',\n",
       " 'XLMroberta_base_offensive_only_kannada',\n",
       " 'Distilbert_m_base_cased_offensive_only_kannada',\n",
       " 'Mbert_base_cased_kannada_weighted',\n",
       " 'XLMroberta_custom_pretrained_kannada',\n",
       " 'Mbert_base_cased_kannada',\n",
       " 'Mbert_base_cased_collated_kannada',\n",
       " 'Indic_bert_offensive_only_kannada_weighted',\n",
       " 'Distilbert_m_base_cased_collated_kannada',\n",
       " 'Distilbert_m_base_cased_collated_kannada_weighted',\n",
       " 'XLMroberta_large_collated_kannada',\n",
       " 'Distilbert_m_base_cased_offensive_only_kannada_weighted']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Select\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "[x for x in listdir('../../finetuned_berts/') if 'kannada' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "tokenizers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at ../finetuned_berts/XLMroberta_custom_pretrained_tamil_weighted and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, BertTokenizer, XLMRobertaTokenizer\n",
    "\n",
    "model_names = [\n",
    "    'Mbert_base_cased_Tamil',\n",
    "    'XLMroberta_custom_pretrained_tamil_weighted',\n",
    "]\n",
    "tokenizers = [\n",
    "    BertTokenizer.from_pretrained('bert-base-multilingual-cased'),\n",
    "    XLMRobertaTokenizer.from_pretrained('xlm-roberta-base'),\n",
    "]\n",
    "\n",
    "for name in model_names:\n",
    "    model = AutoModel.from_pretrained(os.path.join('../../finetuned_berts/', name))\n",
    "    model.eval()\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_dim = np.sum([1024 if 'large' in name else 768 for name in model_names])\n",
    "lin_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading Model\n",
    "# #saved_model_filename = 'XLMroberta_base_kannada_weighted.pth'\n",
    "# saved_model_filename = 'XLMroberta_large_kannada.pth'\n",
    "# from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, XLMRobertaModel\n",
    "# tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')\n",
    "# model = XLMRobertaModel.from_pretrained('xlm-roberta-large')\n",
    "\n",
    "# load_dict = torch.load(os.path.join('../../finetuned_models/', saved_model_filename))\n",
    "# load_dict = {k.split('roberta.')[-1]: v for k, v in load_dict.items()}\n",
    "# load_dict = {k: v for k, v in load_dict.items() if k in model.state_dict()}\n",
    "# model.load_state_dict(load_dict, strict=False)\n",
    "# model.eval()\n",
    "\n",
    "# models.append(model)\n",
    "# tokenizers.append(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Indic Bert\n",
    "# saved_model_filename = 'Indic_bert_Tamil.pth'\n",
    "# from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "# model = AutoModel.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "\n",
    "# load_dict = torch.load(os.path.join('../../finetuned_models/', saved_model_filename))\n",
    "# load_dict = {k.split('albert.')[-1]: v for k, v in load_dict.items()}\n",
    "# load_dict = {k: v for k, v in load_dict.items() if k in model.state_dict()}\n",
    "# model.load_state_dict(load_dict, strict=False)\n",
    "# model.eval()\n",
    "\n",
    "# models.append(model)\n",
    "# tokenizers.append(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'Not_offensive': 0, \n",
    "    'not-Tamil': 1, \n",
    "    'Offensive_Targeted_Insult_Other': 2, \n",
    "    'Offensive_Targeted_Insult_Group': 3, \n",
    "    'Offensive_Untargetede': 4, \n",
    "    'Offensive_Targeted_Insult_Individual': 5\n",
    "}\n",
    "\n",
    "# Collecting Text and Labels\n",
    "train_batch_sentences = list(tamil_train['text'])\n",
    "train_batch_labels =  [label_mapping[x] for x in tamil_train['label']]\n",
    "dev_batch_sentences = list(tamil_dev['text'])\n",
    "dev_batch_labels =  [label_mapping[x] for x in tamil_dev['label']]\n",
    "test_batch_sentences = list(tamil_test['text'])\n",
    "\n",
    "# Convert to Tensor\n",
    "train_encodings = [tokenizer(train_batch_sentences, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\") for tokenizer in tokenizers]\n",
    "train_labels = torch.tensor(train_batch_labels)\n",
    "dev_encodings = [tokenizer(dev_batch_sentences, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\") for tokenizer in tokenizers]\n",
    "dev_labels = torch.tensor(dev_batch_labels)\n",
    "test_encodings = [tokenizer(test_batch_sentences, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\") for tokenizer in tokenizers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Tamil_Offensive_Dataset(Dataset):\n",
    "    def __init__(self, encodings, labels = None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.n_models = len(encodings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        for i in range(self.n_models):\n",
    "            item.update({key+'_'+str(i): torch.tensor(val[idx]) for key, val in self.encodings[i].items()})\n",
    "        item['index'] = idx\n",
    "        if self.labels != None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        else:\n",
    "            item['labels'] = torch.tensor(1)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[0]['input_ids'])\n",
    "\n",
    "# Defining Datasets\n",
    "train_dataset = Tamil_Offensive_Dataset(train_encodings, train_labels)\n",
    "dev_dataset = Tamil_Offensive_Dataset(dev_encodings, dev_labels)\n",
    "test_dataset = Tamil_Offensive_Dataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# Basic Fully-Connected (Linear => BatchNorm => ReLU)\n",
    "class BasicFC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicFC, self).__init__()\n",
    "        self.fc = nn.Linear(in_channels, out_channels, **kwargs)\n",
    "        self.bn = nn.BatchNorm1d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "class FusionNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, H3, D_out):\n",
    "        super(FusionNet, self).__init__()\n",
    "        self.linear1_1 = BasicFC(D_in, H1)\n",
    "        self.linear1_2 = BasicFC(H1, H2)\n",
    "        self.linear1_3 = BasicFC(H2, H3)\n",
    "        self.dp = nn.Dropout(0.1)\n",
    "        self.linear2 = torch.nn.Linear(H3, D_out, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_relu_1 = self.linear1_1(x)\n",
    "        h_relu_2 = self.dp(self.linear1_2(h_relu_1))\n",
    "        h_relu_3 = self.dp(self.linear1_3(h_relu_2))\n",
    "        y_pred = self.linear2(h_relu_3)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimiser\n",
    "from transformers import AdamW\n",
    "from pytorch_pretrained_bert.optimization import BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Fn\n",
    "XE_loss_function = nn.CrossEntropyLoss(reduction='mean').float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1_Loss(nn.Module):\n",
    "    '''Calculate F1 score. Can work with gpu tensors\n",
    "    \n",
    "    The original implmentation is written by Michal Haltuf on Kaggle.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        `ndim` == 1. epsilon <= val <= 1\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n",
    "    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\n",
    "    '''\n",
    "    def __init__(self, epsilon=1e-7, n_labels = 6):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "    def forward(self, y_pred, y_true,):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.n_labels).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "        \n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n",
    "        return 1 - f1.mean()\n",
    "\n",
    "F1_loss_function = F1_Loss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_f1_loss = False\n",
    "if use_f1_loss:\n",
    "    loss_function = F1_loss_function\n",
    "else:\n",
    "    loss_function = XE_loss_function\n",
    "    #loss_function = multi_loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_extra_embeds = [\n",
    "     'cnn_128',\n",
    "     #'cnn_64',\n",
    "     #'sentbert',\n",
    "#      'laser_ta',\n",
    "#      'laser_en',\n",
    "]\n",
    "\n",
    "embeds_files = {\n",
    "    'cnn_128': ['../../sentence_embeddings/cnn_emb_train_128_tamil.npy', '../../sentence_embeddings/cnn_emb_dev_128_tamil.npy', '../../sentence_embeddings/cnn_emb_test_128_tamil.npy'],\n",
    "    'cnn_64': ['../../sentence_embeddings/cnn_skipgram_emb_train.npy', '../../sentence_embeddings/cnn_skipgram_emb_dev.npy', '../../sentence_embeddings/cnn_skipgram_emb_test.npy'],\n",
    "    'laser_ta': ['../../sentence_embeddings/LASER_embeddings_tamil_ta_train.npy', '../../sentence_embeddings/LASER_embeddings_tamil_ta_dev.npy'],\n",
    "    'laser_en': ['../../sentence_embeddings/LASER_embeddings_tamil_en_train.npy', '../../sentence_embeddings/LASER_embeddings_tamil_en_dev.npy'],\n",
    "    'sentbert': ['../../sentence_embeddings/sentence_bert_train.npy', '../../sentence_embeddings/sentence_bert_dev.npy'],\n",
    "}\n",
    "\n",
    "train_embeddings = [np.load(embeds_files[embname][0]) for embname in add_extra_embeds]\n",
    "dev_embeddings = [np.load(embeds_files[embname][1]) for embname in add_extra_embeds]\n",
    "test_embeddings = [np.load(embeds_files[embname][2]) for embname in add_extra_embeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35139, 128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_extra_embeds = len(add_extra_embeds)\n",
    "len_extra_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_extra_embeds = np.sum([train_embeddings[i].shape[1] for i in range(len_extra_embeds)])\n",
    "dim_extra_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664\n"
     ]
    }
   ],
   "source": [
    "print(lin_dim + dim_extra_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "Epoch 0\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ebc88477cd40ab971f51dd557c3e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4388a6c82c46e7a3c68c1ffd9db307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=275.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.89      0.89      0.89      3193\n",
      "                           not-Tamil       0.82      0.87      0.85       172\n",
      "     Offensive_Targeted_Insult_Other       0.04      0.02      0.02        65\n",
      "     Offensive_Targeted_Insult_Group       0.34      0.41      0.37       295\n",
      "               Offensive_Untargetede       0.39      0.42      0.40       356\n",
      "Offensive_Targeted_Insult_Individual       0.51      0.41      0.46       307\n",
      "\n",
      "                            accuracy                           0.77      4388\n",
      "                           macro avg       0.50      0.50      0.50      4388\n",
      "                        weighted avg       0.77      0.77      0.77      4388\n",
      "\n",
      "Epoch 0, Val Loss = 1.0347464641657742, Val F1 = 0.4977503074658605, Best Val f1 = 0.4977503074658605, stagnant_t = 0\n",
      "==========================================================\n",
      "Epoch 1\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5680546998df4f4fbf0348016b6ad3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd4c6ff4dca4479886bc3758c92e70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=275.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.89      0.88      0.88      3193\n",
      "                           not-Tamil       0.84      0.85      0.85       172\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
      "     Offensive_Targeted_Insult_Group       0.35      0.41      0.38       295\n",
      "               Offensive_Untargetede       0.39      0.44      0.41       356\n",
      "Offensive_Targeted_Insult_Individual       0.47      0.44      0.45       307\n",
      "\n",
      "                            accuracy                           0.77      4388\n",
      "                           macro avg       0.49      0.50      0.50      4388\n",
      "                        weighted avg       0.77      0.77      0.77      4388\n",
      "\n",
      "Epoch 1, Val Loss = 0.91070671341636, Val F1 = 0.496401770756378, Best Val f1 = 0.4977503074658605, stagnant_t = 1\n",
      "==========================================================\n",
      "Epoch 2\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0976799296f4e60a61110db31da397a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fe1978a6e34cf48e3287a9df8ff8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=275.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.86      0.92      0.89      3193\n",
      "                           not-Tamil       0.88      0.80      0.84       172\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
      "     Offensive_Targeted_Insult_Group       0.37      0.36      0.36       295\n",
      "               Offensive_Untargetede       0.47      0.35      0.40       356\n",
      "Offensive_Targeted_Insult_Individual       0.49      0.39      0.44       307\n",
      "\n",
      "                            accuracy                           0.78      4388\n",
      "                           macro avg       0.51      0.47      0.49      4388\n",
      "                        weighted avg       0.76      0.78      0.77      4388\n",
      "\n",
      "Epoch 2, Val Loss = 0.7288551826097749, Val F1 = 0.4885005667022395, Best Val f1 = 0.4977503074658605, stagnant_t = 2\n",
      "==========================================================\n",
      "Epoch 3\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6e5633cb6643aca80598b9f5915167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f2b582d07b4e6e93c220ee9665b1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=275.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.88      0.90      0.89      3193\n",
      "                           not-Tamil       0.87      0.81      0.84       172\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
      "     Offensive_Targeted_Insult_Group       0.38      0.32      0.35       295\n",
      "               Offensive_Untargetede       0.39      0.49      0.43       356\n",
      "Offensive_Targeted_Insult_Individual       0.50      0.40      0.44       307\n",
      "\n",
      "                            accuracy                           0.78      4388\n",
      "                           macro avg       0.50      0.49      0.49      4388\n",
      "                        weighted avg       0.77      0.78      0.77      4388\n",
      "\n",
      "Epoch 3, Val Loss = 0.7443472450700676, Val F1 = 0.492798165024041, Best Val f1 = 0.4977503074658605, stagnant_t = 3\n",
      "==========================================================\n",
      "Epoch 4\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31dbed735be4ce08897b7831da086cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806929d2a39c43e290d1e5da875bacad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=275.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.87      0.91      0.89      3193\n",
      "                           not-Tamil       0.87      0.85      0.86       172\n",
      "     Offensive_Targeted_Insult_Other       0.07      0.03      0.04        65\n",
      "     Offensive_Targeted_Insult_Group       0.36      0.34      0.35       295\n",
      "               Offensive_Untargetede       0.40      0.43      0.42       356\n",
      "Offensive_Targeted_Insult_Individual       0.52      0.31      0.39       307\n",
      "\n",
      "                            accuracy                           0.78      4388\n",
      "                           macro avg       0.51      0.48      0.49      4388\n",
      "                        weighted avg       0.76      0.78      0.77      4388\n",
      "\n",
      "Epoch 4, Val Loss = 0.7310985839908771, Val F1 = 0.4919166502007308, Best Val f1 = 0.4977503074658605, stagnant_t = 4\n",
      "==========================================================\n",
      "Epoch 5\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70220a7cea0c470c8cb8fb36a42c06e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53a8b4147174c85a5eee47626a9fbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=275.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.87      0.91      0.89      3193\n",
      "                           not-Tamil       0.86      0.83      0.84       172\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
      "     Offensive_Targeted_Insult_Group       0.32      0.41      0.36       295\n",
      "               Offensive_Untargetede       0.45      0.36      0.40       356\n",
      "Offensive_Targeted_Insult_Individual       0.52      0.34      0.41       307\n",
      "\n",
      "                            accuracy                           0.78      4388\n",
      "                           macro avg       0.50      0.47      0.48      4388\n",
      "                        weighted avg       0.76      0.78      0.77      4388\n",
      "\n",
      "Epoch 5, Val Loss = 0.7610415003110066, Val F1 = 0.4834264749779868, Best Val f1 = 0.4977503074658605, stagnant_t = 5\n",
      "No increase for 5 epochs, Stopping ...\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "fusion_classifier = FusionNet(int(lin_dim + dim_extra_embeds), 1024, 256, 64, 6)\n",
    "# Optimiser\n",
    "optimizer = AdamW(fusion_classifier.parameters(), lr=1e-5)\n",
    "mo,ex_em = \"\",\"\"\n",
    "for mod in model_names:\n",
    "    mo += mod\n",
    "for em in add_extra_embeds:\n",
    "    ex_em += em\n",
    "model_name = 'fusion_tamil_'+mo+'_'+ex_em\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "fusion_classifier.to(device)\n",
    "for model in models:\n",
    "    model.to(device)\n",
    "best_val_f1 = 0\n",
    "count = 0\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "for epoch in range(100):\n",
    "    fusion_classifier.train()\n",
    "    print(\"==========================================================\")\n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "    print(\"Train\")\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs_all = []\n",
    "        for i in range(n_models):\n",
    "            model = models[i]\n",
    "            input_ids = batch['input_ids'+'_'+str(i)].to(device)\n",
    "            attention_mask = batch['attention_mask'+'_'+str(i)].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            outputs_all.append(outputs[1])\n",
    "        \n",
    "        for i in range(len_extra_embeds):\n",
    "            outputs_all.append(torch.Tensor(train_embeddings[i][batch['index'], :]).to(device))\n",
    "            \n",
    "        bert_output = torch.cat(outputs_all, dim = -1) \n",
    "        out = fusion_classifier(bert_output)\n",
    "        loss = loss_function(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"Dev\")\n",
    "    dev_preds = []\n",
    "    fusion_classifier.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for batch in tqdm(dev_loader):\n",
    "            outputs_all = []\n",
    "            for i in range(n_models):\n",
    "                model = models[i]\n",
    "                input_ids = batch['input_ids'+'_'+str(i)].to(device)\n",
    "                attention_mask = batch['attention_mask'+'_'+str(i)].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                outputs_all.append(outputs[1])\n",
    "                \n",
    "            for i in range(len_extra_embeds):\n",
    "                outputs_all.append(torch.Tensor(dev_embeddings[i][batch['index'], :]).to(device))\n",
    "\n",
    "            bert_output = torch.cat(outputs_all, dim = -1) \n",
    "            out = fusion_classifier(bert_output)\n",
    "            loss = loss_function(out, labels)\n",
    "            total_val_loss += loss.item()/len(dev_loader)\n",
    "            \n",
    "            for logits in out.cpu().numpy():\n",
    "                dev_preds.append(np.argmax(logits))\n",
    "    \n",
    "    y_true = dev_batch_labels\n",
    "    y_pred = dev_preds\n",
    "    target_names = label_mapping.keys()\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names)\n",
    "    val_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    if val_f1 > best_val_f1:\n",
    "        PATH = '../../finetuned_models/' + model_name + '.pth'\n",
    "        torch.save(fusion_classifier.state_dict(), PATH)\n",
    "        best_val_f1 = val_f1\n",
    "        best_model = copy.deepcopy(fusion_classifier)\n",
    "        count = 0\n",
    "    else:\n",
    "        count += 1\n",
    "    \n",
    "    print(report)\n",
    "    print(\"Epoch {}, Val Loss = {}, Val F1 = {}, Best Val f1 = {}, stagnant_t = {}\".format(epoch, total_val_loss, val_f1, best_val_f1, count))\n",
    "    if count == 5:\n",
    "        print(\"No increase for 5 epochs, Stopping ...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4977503074658605"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model predictions on Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c44dad60f4c40f78f8df4a636d2d02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=275.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_preds = []\n",
    "dev_probs = []\n",
    "best_model.eval()\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch in tqdm(dev_loader):\n",
    "        outputs_all = []\n",
    "        for i in range(n_models):\n",
    "            model = models[i]\n",
    "            input_ids = batch['input_ids'+'_'+str(i)].to(device)\n",
    "            attention_mask = batch['attention_mask'+'_'+str(i)].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            outputs_all.append(outputs[1])\n",
    "\n",
    "        for i in range(len_extra_embeds):\n",
    "            outputs_all.append(torch.Tensor(dev_embeddings[i][batch['index'], :]).to(device))\n",
    "\n",
    "        bert_output = torch.cat(outputs_all, dim = -1) \n",
    "        out = best_model(bert_output)\n",
    "\n",
    "        for logits in out.cpu().numpy():\n",
    "            dev_preds.append(np.argmax(logits))\n",
    "        for logits in out.cpu().numpy():\n",
    "            dev_probs.append(np.exp(logits)/np.sum(np.exp(logits)))\n",
    "\n",
    "y_true = dev_batch_labels\n",
    "y_pred = dev_preds\n",
    "target_names = label_mapping.keys()\n",
    "report = classification_report(y_true, y_pred, target_names=target_names)\n",
    "val_f1 = f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.89      0.89      0.89      3193\n",
      "                           not-Tamil       0.82      0.87      0.85       172\n",
      "     Offensive_Targeted_Insult_Other       0.04      0.02      0.02        65\n",
      "     Offensive_Targeted_Insult_Group       0.34      0.41      0.37       295\n",
      "               Offensive_Untargetede       0.39      0.42      0.40       356\n",
      "Offensive_Targeted_Insult_Individual       0.51      0.41      0.46       307\n",
      "\n",
      "                            accuracy                           0.77      4388\n",
      "                           macro avg       0.50      0.50      0.50      4388\n",
      "                        weighted avg       0.77      0.77      0.77      4388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4977503074658605"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4388, 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_probs = np.array(dev_probs)\n",
    "dev_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SAVE PREDS\n",
    "np.save('dev_probs/dev_preds_'+model_name+'.npy', dev_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4392"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model predictions on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc8556402924344834ebcc0962f6f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=275.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "test_preds = []\n",
    "test_probs = []\n",
    "total_val_loss = 0\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch in tqdm(test_loader):\n",
    "        outputs_all = []\n",
    "        for i in range(n_models):\n",
    "            model = models[i]\n",
    "            input_ids = batch['input_ids'+'_'+str(i)].to(device)\n",
    "            attention_mask = batch['attention_mask'+'_'+str(i)].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            outputs_all.append(outputs[1])\n",
    "\n",
    "        for i in range(len_extra_embeds):\n",
    "            outputs_all.append(torch.Tensor(test_embeddings[i][batch['index'], :]).to(device))\n",
    "\n",
    "        bert_output = torch.cat(outputs_all, dim = -1) \n",
    "        out = best_model(bert_output)\n",
    " \n",
    "        for logits in out.cpu().numpy():\n",
    "            test_preds.append(np.argmax(logits))\n",
    "        for logits in out.cpu().numpy():\n",
    "            test_probs.append(np.exp(logits)/np.sum(np.exp(logits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs = np.array(test_probs)\n",
    "test_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SAVE PREDS\n",
    "np.save('test_probs/test_preds_'+model_name+'.npy', test_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save config in dict for predictions and ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "dict['pth_name'] = model_name\n",
    "dict['model'] = model_names\n",
    "dict['pretrained_keys'] = ['xlm-roberta-large','bert-base-multilingual-cased']\n",
    "#dict['pretrained_keys'] = ['xlm-roberta-base','xlm-roberta-base','bert-base-multilingual-cased',\"ai4bharat/indic-bert\"]\n",
    "dict['extra_embeds'] = add_extra_embeds\n",
    "dict['length'] = lin_dim + dim_extra_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_tot = 'dicts/'+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(str(model_name_tot)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Preds - Get predictions from individual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Dataloaders\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False)\n",
    "fusion_classifier.load_state_dict(torch.load('../../finetuned_models/' + model_name + '.pth'))\n",
    "fusion_classifier.eval()\n",
    "\n",
    "dev_preds = []\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch in tqdm(dev_loader):\n",
    "        outputs_all = []\n",
    "        for i in range(n_models):\n",
    "            model = models[i]\n",
    "            input_ids = batch['input_ids'+'_'+str(i)].to(device)\n",
    "            attention_mask = batch['attention_mask'+'_'+str(i)].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            outputs_all.append(outputs[1])\n",
    "        \n",
    "        for i in range(len_extra_embeds):\n",
    "                outputs_all.append(torch.Tensor(dev_embeddings[i][batch['index'], :]).to(device))\n",
    "\n",
    "        bert_output = torch.cat(outputs_all, dim = -1) \n",
    "        out = fusion_classifier(bert_output)\n",
    "            \n",
    "        for logits in out.cpu().numpy():\n",
    "            dev_preds.append(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = dev_batch_labels\n",
    "y_pred = dev_preds\n",
    "target_names = label_mapping.keys()\n",
    "report = classification_report(y_true, y_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../../dev_preds/\" + model_name + \".csv\", dev_preds, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nlp]",
   "language": "python",
   "name": "conda-env-.conda-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
