{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV from link\n",
    "def read_csv_from_link(url):\n",
    "    path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "    df = pd.read_csv(path,delimiter=\"\\t\",error_bad_lines=False, header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2399: expected 2 fields, saw 3\\nSkipping line 2525: expected 2 fields, saw 3\\n'\n",
      "b'Skipping line 777: expected 2 fields, saw 3\\n'\n"
     ]
    }
   ],
   "source": [
    "# Loading All Data\n",
    "tamil_train = read_csv_from_link('https://drive.google.com/file/d/15auwrFAlq52JJ61u7eSfnhT9rZtI5sjk/view?usp=sharing')\n",
    "tamil_dev = read_csv_from_link('https://drive.google.com/file/d/1Jme-Oftjm7OgfMNLKQs1mO_cnsQmznRI/view?usp=sharing')\n",
    "mal_train = read_csv_from_link('https://drive.google.com/file/d/13JCCr-IjZK7uhbLXeufptr_AxvsKinVl/view?usp=sharing')\n",
    "mal_dev = read_csv_from_link('https://drive.google.com/file/d/1J0msLpLoM6gmXkjC6DFeQ8CG_rrLvjnM/view?usp=sharing')\n",
    "kannada_train = read_csv_from_link('https://drive.google.com/file/d/1XuOhSpdK8qsbO-lZHrIcVaU5FsCXc05T/view?usp=sharing')\n",
    "kannada_dev = read_csv_from_link('https://drive.google.com/file/d/164zYZOeXIwt5jl3NggJU0CWRyD2fRT9z/view?usp=sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamil Preprocess\n",
    "tamil_train = tamil_train.iloc[:, 0:2]\n",
    "tamil_train = tamil_train.rename(columns={0: \"text\", 1: \"label\"})\n",
    "\n",
    "tamil_dev = tamil_dev.iloc[:, 0:2]\n",
    "tamil_dev = tamil_dev.rename(columns={0: \"text\", 1: \"label\"})\n",
    "\n",
    "# Stats\n",
    "tamil_train['label'] = pd.Categorical(tamil_train.label)\n",
    "tamil_dev['label'] = pd.Categorical(tamil_dev.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mdevi                   \u001b[m  Sat Jan  9 01:58:13 2021  \u001b[1m\u001b[30m450.51.05\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-12GB\u001b[m |\u001b[31m 36'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 4959\u001b[m / \u001b[33m12198\u001b[m MB | \u001b[1m\u001b[30mpunyajoy\u001b[m(\u001b[33m4953M\u001b[m) \u001b[1m\u001b[30mgdm\u001b[m(\u001b[33m4M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 46'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m16275\u001b[m / \u001b[33m16280\u001b[m MB | \u001b[1m\u001b[30mpunyajoy\u001b[m(\u001b[33m13875M\u001b[m) \u001b[1m\u001b[30mpunyajoy\u001b[m(\u001b[33m1943M\u001b[m) \u001b[1m\u001b[30mpunyajoy\u001b[m(\u001b[33m451M\u001b[m) \u001b[1m\u001b[30mgdm\u001b[m(\u001b[33m4M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Nos: 2\n",
      "Tesla P100-PCIE-12GB\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Nos: {}\".format(torch.cuda.device_count()))\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_name(1))\n",
    "\n",
    "# Change Device - CPU/GPU-0/GPU-1\n",
    "torch.cuda.set_device(0)\n",
    "device = 'cuda'\n",
    "device = device if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter Path of Saved model here in torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fusion_kannada_XLMroberta_base_kannadaMbert_base_cased_kannada_cnn_128laser_knlaser_en.pth',\n",
       " 'MURIL_cased_temp_offensive_only_kannada.pth',\n",
       " 'Indic_bert_collated_Tamil.pth',\n",
       " 'XLMroberta_custom_pretrained_Malayalam.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannadaXLMroberta_custom_pretrained_kannadaMbert_base_cased_kannadaIndic_bert_kannada_cnn_128laser_knlaser_en.pth',\n",
       " 'XLMroberta_base_offensive_only_malayalam_weighted.pth',\n",
       " 'XLMroberta_large_collated_kannada.pth',\n",
       " 'Scratch_custom.pth',\n",
       " 'XLMroberta_large_kannada.pth',\n",
       " 'Distilbert_m_base_cased_Malayalam_weighted.pth',\n",
       " 'Tamillion_X.pth',\n",
       " 'fusion_tamil_XLMroberta_base_TamilXLMroberta_custom_pretrained_tamil_weighted_cnn_128.pth',\n",
       " 'Indic_bert_collated_malayalam_weighted.pth',\n",
       " 'XLMroberta_custom_pretrained_collated_malayalam_weighted.pth',\n",
       " 'XLMroberta_large_offensive_only_Tamil.pth',\n",
       " 'XLMroberta_base_Tamil_soft_F1_loss.pth',\n",
       " 'Indic_bert_Malayalam_weighted.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannada_weightedMbert_base_cased_kannada_weightedMURIL_cased_temp_kannada_cnn_128laser_kn.pth',\n",
       " 'MURIL_cased_temp_offensive_only_malayalam.pth',\n",
       " 'XLMroberta_base_kannada.pth',\n",
       " 'fusion_kannada_XLMroberta_large_kannada_weighted_cnn_128.pth',\n",
       " 'XLMroberta_large_tamil_weighted.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannadaIndic_bert_kannada_.pth',\n",
       " 'Mbert_base_cased_collated_malayalam.pth',\n",
       " 'Distilbert_m_base_cased_collated_malayalam.pth',\n",
       " 'MURIL_cased_temp_collated_kannada.pth',\n",
       " 'Indic_bert_offensive_only_Tamil.pth',\n",
       " 'fusion_tamil_XLMroberta_base_TamilXLMroberta_large_Tamil_cnn_128laser_talaser_en.pth',\n",
       " 'MURIL_cased_temp_kannada.pth',\n",
       " 'Distilbert_m_base_cased_Tamil.pth',\n",
       " 'XLMroberta_base_collated_kannada_weighted.pth',\n",
       " 'XLMroberta_base_Malayalam_weighted.pth',\n",
       " '.ipynb_checkpoints',\n",
       " 'Distilbert_m_base_cased_Malayalam.pth',\n",
       " 'XLMroberta_large_Tamil.pth',\n",
       " 'XLMroberta_custom_pretrained_Malayalam_weighted.pth',\n",
       " 'Mbert_base_cased_Tamil[ 0.23034415  4.0278542  12.89977974  2.29037935  2.01531315  2.4995732 ].pth',\n",
       " 'Distilbert_m_base_cased_Tamil_exp.pth',\n",
       " 'fusion_kannada_XLMroberta_large_kannadaMbert_base_cased_kannada_cnn_128.pth',\n",
       " 'Mbert_base_cased_Tamil_exp.pth',\n",
       " 'XLMroberta_custom_pretrained_collated_kannada.pth',\n",
       " 'MURIL_cased_temp_Malayalam.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannadaMbert_base_cased_kannada_.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannada_weighted_cnn_128.pth',\n",
       " 'XLMNet_large_Tamil.pth',\n",
       " 'XLMroberta_large_Malayalam_weighted.pth',\n",
       " 'XLMroberta_base_collated_malayalam_weighted.pth',\n",
       " 'fusion_malayalam_XLMroberta_base_Malayalam_cnn_128.pth',\n",
       " 'MURIL_cased_temp_collated_kannada_weighted.pth',\n",
       " 'XLMroberta_large_collated_kannada_weighted.pth',\n",
       " 'fusion_malayalam_XLMroberta_custom_pretrained_MalayalamXLMroberta_base_MalayalamMbert_base_cased_Malayalam_weighted_cnn_128.pth',\n",
       " 'Distilbert_m_base_cased_offensive_only_malayalam_weighted.pth',\n",
       " 'Mbert_base_cased_Malayalam.pth',\n",
       " 'XLMroberta_base_offensive_only_Tamil.pth',\n",
       " 'XLMroberta_base_Tamil.pth',\n",
       " 'Indic_bert_collated_malayalam.pth',\n",
       " 'fusion_kannada_XLMroberta_custom_pretrained_kannada_cnn_128.pth',\n",
       " 'Mbert_base_cased_collated_Tamil.pth',\n",
       " 'XLMroberta_base_collated_kannada.pth',\n",
       " 'XLMroberta_base_offensive_only_kannada.pth',\n",
       " 'XLMroberta_large_collated_Tamil.pth',\n",
       " 'MURIL_cased_temp_offensive_only_malayalam_weighted.pth',\n",
       " 'XLMroberta_large_collated_malayalam.pth',\n",
       " 'Indic_bert_Tamil.pth',\n",
       " 'Indic_bert_kannada.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannadaXLMroberta_custom_pretrained_kannadaMbert_base_cased_kannada_cnn_128.pth',\n",
       " 'Distilbert_m_base_cased_offensive_only_Tamil.pth',\n",
       " 'Indic_bert_kannada_weighted.pth',\n",
       " 'MURIL_cased_temp_Tamil.pth',\n",
       " 'fusion_malayalam_XLMroberta_base_MalayalamXLMroberta_large_MalayalamMbert_base_cased_Malayalam_cnn_128.pth',\n",
       " 'Custom_Roberta_LM.pth',\n",
       " 'Indic_bert_collated_Tamil_weighted.pth',\n",
       " 'fusion_tamil_XLMroberta_base_TamilXLMroberta_large_TamilMbert_base_cased_Tamil_cnn_128.pth',\n",
       " 'XLMroberta_base_Malayalam.pth',\n",
       " 'fusion_kannada_v1.pth',\n",
       " 'XLMroberta_large_offensive_only_kannada_weighted.pth',\n",
       " 'XLMroberta_custom_pretrained_offensive_only_Tamil.pth',\n",
       " 'Distilbert_m_base_cased_collated_kannada_weighted.pth',\n",
       " 'MURIL_cased_temp_kannada_weighted.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannadaXLMroberta_custom_pretrained_kannada_cnn_128.pth',\n",
       " 'Mbert_base_cased_collated_kannada.pth',\n",
       " 'XLMroberta_large_offensive_only_malayalam.pth',\n",
       " 'fusion_kannada_Mbert_base_cased_kannada_cnn_128.pth',\n",
       " 'Mbert_base_cased_collated_kannada_weighted.pth',\n",
       " 'Mbert_base_cased_offensive_only_malayalam.pth',\n",
       " 'Indic_bert_offensive_only_malayalam.pth',\n",
       " 'test.pth',\n",
       " 'fusion_malayalam_XLMroberta_base_MalayalamMbert_base_cased_Malayalam_cnn_128.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannadaMbert_base_cased_kannadaMURIL_cased_temp_kannada_cnn_128.pth',\n",
       " 'Distilbert_m_base_cased_collated_kannada.pth',\n",
       " 'XLMroberta_custom_pretrained_offensive_only_malayalam_weighted.pth',\n",
       " 'XLMroberta_from_custom_pretrained_Tamil.pth',\n",
       " 'Mbert_base_cased_Malayalam_weighted.pth',\n",
       " 'XLMroberta_custom_pretrained_collated_malayalam.pth',\n",
       " 'fusion_malayalam_XLMroberta_base_MalayalamXLMroberta_large_TamilMbert_base_cased_Malayalam_cnn_128.pth',\n",
       " 'Distilbert_m_base_cased_offensive_only_malayalam.pth',\n",
       " 'XLMroberta_custom_pretrained_tamil_weighted.pth',\n",
       " 'fusion_kannada_XLMroberta_base_Tamil_cnn_128.pth',\n",
       " 'fusion_v1.pth',\n",
       " 'fusion_kannada_Mbert_base_cased_kannadaMURIL_cased_temp_kannada_cnn_128laser_knlaser_en.pth',\n",
       " 'Mbert_base_cased_tamil_weighted.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannadaMbert_base_cased_kannadaMURIL_cased_temp_kannada_cnn_128laser_kn.pth',\n",
       " 'XLMroberta_large_Malayalam.pth',\n",
       " 'XLMroberta_large_collated_malayalam_weighted.pth',\n",
       " 'fusion_malayalam_XLMroberta_custom_pretrained_MalayalamXLMroberta_large_Malayalam_cnn_128.pth',\n",
       " 'XLMroberta_large_kannada_weighted.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannada_cnn_128.pth',\n",
       " 'Mbert_base_cased_kannada.pth',\n",
       " 'Distilbert_m_base_cased_kannada.pth',\n",
       " 'fusion_kannada_v1_F1.pth',\n",
       " 'XLMroberta_custom_pretrained_kannada.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannadaXLMroberta_custom_pretrained_kannadaMbert_base_cased_kannada_cnn_128laser_knlaser_en.pth',\n",
       " 'XLMroberta_base_offensive_only_kannada_weighted.pth',\n",
       " 'MURIL_cased_temp_offensive_only_kannada_weighted.pth',\n",
       " 'XLMroberta_custom_pretrained_offensive_only_kannada.pth',\n",
       " 'fusion_tamil_XLMroberta_base_TamilXLMroberta_large_Tamil_cnn_128.pth',\n",
       " 'XLMroberta_custom_pretrained_Tamil_Weighted[0.01 1.   1.   1.   1.   1.  ].pth',\n",
       " 'XLMroberta_base_collated_malayalam.pth',\n",
       " 'Mbert_base_cased_collated_Tamil_weighted.pth',\n",
       " 'XLMroberta_base_kannada_weighted.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannadaMbert_base_cased_kannada_cnn_128.pth',\n",
       " 'XLMroberta_base_collated_Tamil.pth',\n",
       " 'Mbert_base_cased_kannada_weighted.pth',\n",
       " 'MURIL_cased_temp_tamil_weighted.pth',\n",
       " 'fusion_malayalam_XLMroberta_custom_pretrained_MalayalamXLMroberta_large_Tamil_cnn_128.pth',\n",
       " 'XLMroberta_custom_pretrained_collated_kannada_weighted.pth',\n",
       " 'Indic_bert_Tamil_exp.pth',\n",
       " 'Indic_bert_tamil_weighted.pth',\n",
       " 'fusion_tamil_XLMroberta_large_TamilMbert_base_cased_Tamil_cnn_128.pth',\n",
       " 'fusion_tamil_Mbert_base_cased_TamilXLMroberta_custom_pretrained_tamil_weighted_cnn_128.pth',\n",
       " 'MURIL_cased_temp_collated_malayalam.pth',\n",
       " 'fusion_tamil_XLMroberta_base_TamilMbert_base_cased_Tamil_cnn_128.pth',\n",
       " 'Indic_bert_collated_kannada_weighted.pth',\n",
       " 'Distilbert_m_base_cased_offensive_only_kannada.pth',\n",
       " 'XLMroberta_large_offensive_only_kannada.pth',\n",
       " 'Distilbert_m_base_cased_collated_malayalam_weighted.pth',\n",
       " 'Mbert_base_cased_offensive_only_kannada_weighted.pth',\n",
       " 'Distilbert_m_base_cased_kannada_weighted.pth',\n",
       " 'Indic_bert_Malayalam.pth',\n",
       " 'fusion_kannada_MURIL_cased_temp_kannada_cnn_128.pth',\n",
       " 'Indic_bert_offensive_only_kannada_weighted.pth',\n",
       " 'XLMroberta_base_offensive_only_Tamil_weighted.pth',\n",
       " 'XLMroberta_base_tamil_weighted.pth',\n",
       " 'Mbert_base_cased_offensive_only_kannada.pth',\n",
       " 'Mbert_base_cased_Tamil.pth',\n",
       " 'MURIL_cased_temp_Malayalam_weighted.pth',\n",
       " 'Distilbert_m_base_cased_tamil_weighted.pth',\n",
       " 'Indic_bert_offensive_only_kannada.pth',\n",
       " 'XLMroberta_custom_pretrained_offensive_only_malayalam.pth',\n",
       " 'fusion_malayalam_XLMroberta_base_MalayalamMbert_base_cased_Malayalam_.pth',\n",
       " 'fusion_tamil_MURIL_cased_temp_TamilXLMroberta_custom_pretrained_tamil_weighted_cnn_128.pth',\n",
       " 'XLMroberta_custom_pretrained_kannada_weighted.pth',\n",
       " 'XLMroberta_custom_pretrained_offensive_only_kannada_weighted.pth',\n",
       " 'fusion_kannada_XLMroberta_base_kannada_.pth',\n",
       " 'Indic_bert_collated_kannada.pth',\n",
       " 'Mbert_base_cased_offensive_only_Tamil.pth',\n",
       " 'Mbert_base_cased_collated_malayalam_weighted.pth',\n",
       " 'Indic_bert_offensive_only_malayalam_weighted.pth',\n",
       " 'XLMroberta_base_collated_Tamil_weighted.pth',\n",
       " 'XLMroberta_large_offensive_only_malayalam_weighted.pth',\n",
       " 'Mbert_base_cased_offensive_only_malayalam_weighted.pth',\n",
       " 'XLMroberta_base_offensive_only_malayalam.pth',\n",
       " 'fusion_malayalam_XLMroberta_custom_pretrained_MalayalamMbert_base_cased_Malayalam_cnn_128.pth',\n",
       " 'Distilbert_m_base_cased_offensive_only_kannada_weighted.pth',\n",
       " 'MURIL_cased_temp_collated_malayalam_weighted.pth']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Select\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "f = listdir('../../finetuned_models/')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_filenames = [\n",
    "    'XLMroberta_base_Tamil.pth',\n",
    "    'Indic_bert_Tamil.pth',\n",
    "    'Mbert_base_cased_Tamil.pth',\n",
    "    'XLMroberta_custom_pretrained_Tamil_Weighted[0.01 1.   1.   1.   1.   1.  ].pth',\n",
    "    'Mbert_base_cased_Tamil[ 0.23034415  4.0278542  12.89977974  2.29037935  2.01531315  2.4995732 ].pth',\n",
    "    'XLMroberta_from_custom_pretrained_Tamil.pth',\n",
    "    'XLMroberta_large_Tamil.pth',\n",
    "    'Distilbert_m_base_cased_Tamil.pth',\n",
    "    'MURIL_cased_temp_Tamil.pth',\n",
    "    \"XLMroberta_large_tamil_weighted.pth\",\n",
    "    \"XLMroberta_custom_pretrained_tamil_weighted.pth\",\n",
    "    \"Mbert_base_cased_tamil_weighted.pth\",\n",
    "    \"MURIL_cased_temp_tamil_weighted.pth\",\n",
    "    \"Indic_bert_tamil_weighted.pth\",\n",
    "    \"XLMroberta_base_tamil_weighted.pth\",\n",
    "    \"Distilbert_m_base_cased_tamil_weighted.pth\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained_keys = [\n",
    "    'xlm-roberta-base',\n",
    "    'ai4bharat/indic-bert',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'xlm-roberta-base',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'xlm-roberta-base',\n",
    "    'xlm-roberta-large',\n",
    "    'distilbert-base-multilingual-cased',\n",
    "    \"simran-kh/muril-cased-temp\",\n",
    "    'xlm-roberta-large',\n",
    "    'xlm-roberta-base',\n",
    "    'bert-base-multilingual-cased',\n",
    "    \"simran-kh/muril-cased-temp\",\n",
    "    'ai4bharat/indic-bert',\n",
    "    'xlm-roberta-base',\n",
    "    'distilbert-base-multilingual-cased',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = []\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fba289167911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../finetuned_models/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "# Loading Model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "for model_name, pretrained_key in zip(saved_model_filenames, model_pretrained_keys):\n",
    "    \n",
    "    if pretrained_key == 'distilbert-base-multilingual-cased':\n",
    "        tokenizer = BertTokenizer.from_pretrained(pretrained_key)\n",
    "        model = BertForSequenceClassification.from_pretrained(pretrained_key, num_labels=6)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(pretrained_key)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(pretrained_key, num_labels=6)\n",
    "        \n",
    "    state_dict = torch.load(os.path.join('../../finetuned_models/', model_name))\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    \n",
    "    models.append(model)\n",
    "    tokenizers.append(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d3bb9acdeb8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Convert to Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdev_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_batch_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizers' is not defined"
     ]
    }
   ],
   "source": [
    "label_mapping = {\n",
    "    'Not_offensive': 0, \n",
    "    'not-Tamil': 1, \n",
    "    'Offensive_Targeted_Insult_Other': 2, \n",
    "    'Offensive_Targeted_Insult_Group': 3, \n",
    "    'Offensive_Untargetede': 4, \n",
    "    'Offensive_Targeted_Insult_Individual': 5\n",
    "}\n",
    "\n",
    "# Collecting Text and Labels\n",
    "train_batch_sentences = list(tamil_train['text'])\n",
    "train_batch_labels =  [label_mapping[x] for x in tamil_train['label']]\n",
    "dev_batch_sentences = list(tamil_dev['text'])\n",
    "dev_batch_labels =  [label_mapping[x] for x in tamil_dev['label']]\n",
    "\n",
    "# Convert to Tensor\n",
    "train_encodings = [tokenizer(train_batch_sentences, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\") for tokenizer in tokenizers]\n",
    "train_labels = torch.tensor(train_batch_labels)\n",
    "dev_encodings = [tokenizer(dev_batch_sentences, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\") for tokenizer in tokenizers]\n",
    "dev_labels = torch.tensor(dev_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Tamil_Offensive_Dataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Defining Datasets\n",
    "train_datasets = [Tamil_Offensive_Dataset(tenc, train_labels) for tenc in train_encodings]\n",
    "dev_datasets = [Tamil_Offensive_Dataset(denc, dev_labels) for denc in dev_encodings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "all_dev_preds = []\n",
    "\n",
    "for model, dev_dataset in tqdm(zip(models, dev_datasets), total = len(models)):\n",
    "    model.to(device)\n",
    "    # Dataloaders\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    dev_preds = []\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for batch in tqdm(dev_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "            for logits in outputs[1].cpu().numpy():\n",
    "                dev_preds.append(np.exp(logits)/np.sum(np.exp(logits)))\n",
    "    \n",
    "    # Add All together\n",
    "    all_dev_preds.append(dev_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dev_preds, modelname in zip(all_dev_preds, saved_model_filenames):\n",
    "    np.save('../../model_prediction_probs/preds_'+modelname+'.npy', dev_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Select\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "xl = listdir('../../model_prediction_probs/')\n",
    "xo = [x for x in xl if 'GA' not in x and 'offensive' not in x and 'amil' in x and 'coll' not in x and 'fusion' not in x and 'final' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Indic_bert_tamil_weighted.pth.npy',\n",
       " 'MURIL_cased_temp_Tamil.pth.npy',\n",
       " 'MURIL_cased_temp_tamil_weighted.pth.npy',\n",
       " 'XLMroberta_large_tamil_weighted.pth.npy',\n",
       " 'Mbert_base_cased_tamil_weighted.pth.npy',\n",
       " 'Distilbert_m_base_cased_tamil_weighted.pth.npy',\n",
       " 'XLMroberta_large_Tamil.pth.npy',\n",
       " 'Mbert_base_cased_Tamil[ 0.23034415  4.0278542  12.89977974  2.29037935  2.01531315  2.4995732 ].pth.npy',\n",
       " 'XLMroberta_base_Tamil.pth.npy',\n",
       " 'XLMroberta_custom_pretrained_tamil_weighted.pth.npy',\n",
       " 'XLMroberta_base_tamil_weighted.pth.npy',\n",
       " 'Mbert_base_cased_Tamil.pth.npy',\n",
       " 'Indic_bert_Tamil.pth.npy',\n",
       " 'XLMroberta_custom_pretrained_Tamil_Weighted[0.01 1.   1.   1.   1.   1.  ].pth.npy',\n",
       " 'XLMroberta_from_custom_pretrained_Tamil.pth.npy',\n",
       " 'Distilbert_m_base_cased_Tamil.pth.npy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_filenames = xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(load_model_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_filenames = [\n",
    "    'XLMroberta_large_tamil_weighted.pth.npy',\n",
    "    'Distilbert_m_base_cased_Tamil.pth.npy',\n",
    "    'XLMroberta_large_Tamil.pth.npy',\n",
    "    'Mbert_base_cased_Tamil[ 0.23034415  4.0278542  12.89977974  2.29037935  2.01531315  2.4995732 ].pth.npy',\n",
    "    'XLMroberta_base_Tamil.pth.npy',\n",
    "    'Indic_bert_Tamil.pth.npy',\n",
    "    'MURIL_cased_temp_Tamil.pth.npy',\n",
    "    'XLMroberta_from_custom_pretrained_Tamil.pth.npy',\n",
    "    'XLMroberta_custom_pretrained_tamil_weighted.pth.npy',\n",
    "    'Mbert_base_cased_tamil_weighted.pth.npy',\n",
    "    'XLMroberta_custom_pretrained_Tamil_Weighted[0.01 1.   1.   1.   1.   1.  ].pth.npy',\n",
    "    'MURIL_cased_temp_tamil_weighted.pth.npy',\n",
    "    'Indic_bert_tamil_weighted.pth.npy',\n",
    "    'XLMroberta_base_tamil_weighted.pth.npy',\n",
    "    'Mbert_base_cased_Tamil.pth.npy',\n",
    "    'Distilbert_m_base_cased_tamil_weighted.pth.npy'\n",
    "]\n",
    "\n",
    "model_pretrained_keys = [\n",
    "    'xlm-roberta-large',\n",
    "    'distilbert-base-multilingual-cased',\n",
    "    'xlm-roberta-large',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'xlm-roberta-base',\n",
    "    'ai4bharat/indic-bert',\n",
    "    \"simran-kh/muril-cased-temp\",\n",
    "    'xlm-roberta-base',\n",
    "    'xlm-roberta-base',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'xlm-roberta-base',\n",
    "    \"simran-kh/muril-cased-temp\",\n",
    "    'ai4bharat/indic-bert',\n",
    "    'xlm-roberta-base',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'distilbert-base-multilingual-cased',\n",
    "]\n",
    "\n",
    "all_dev_preds = []\n",
    "for pred in load_model_filenames:\n",
    "    all_dev_preds.append(np.load('../../model_prediction_probs/' + pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(load_model_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLMroberta_large_tamil_weighted.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.00      0.00      0.00      3193\n",
      "                           not-Tamil       0.04      1.00      0.08       172\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
      "     Offensive_Targeted_Insult_Group       0.00      0.00      0.00       295\n",
      "               Offensive_Untargetede       0.00      0.00      0.00       356\n",
      "Offensive_Targeted_Insult_Individual       0.00      0.00      0.00       307\n",
      "\n",
      "                            accuracy                           0.04      4388\n",
      "                           macro avg       0.01      0.17      0.01      4388\n",
      "                        weighted avg       0.00      0.04      0.00      4388\n",
      "\n",
      "Distilbert_m_base_cased_Tamil.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.85      0.91      0.88      3193\n",
      "                           not-Tamil       0.81      0.77      0.79       172\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
      "     Offensive_Targeted_Insult_Group       0.32      0.25      0.28       295\n",
      "               Offensive_Untargetede       0.41      0.35      0.38       356\n",
      "Offensive_Targeted_Insult_Individual       0.34      0.33      0.33       307\n",
      "\n",
      "                            accuracy                           0.76      4388\n",
      "                           macro avg       0.46      0.43      0.44      4388\n",
      "                        weighted avg       0.73      0.76      0.74      4388\n",
      "\n",
      "XLMroberta_large_Tamil.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.88      0.91      0.89      3193\n",
      "                           not-Tamil       0.87      0.80      0.83       172\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
      "     Offensive_Targeted_Insult_Group       0.43      0.31      0.36       295\n",
      "               Offensive_Untargetede       0.45      0.44      0.45       356\n",
      "Offensive_Targeted_Insult_Individual       0.44      0.56      0.49       307\n",
      "\n",
      "                            accuracy                           0.79      4388\n",
      "                           macro avg       0.51      0.50      0.50      4388\n",
      "                        weighted avg       0.77      0.79      0.78      4388\n",
      "\n",
      "Mbert_base_cased_Tamil[ 0.23034415  4.0278542  12.89977974  2.29037935  2.01531315  2.4995732 ].pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.92      0.79      0.85      3193\n",
      "                           not-Tamil       0.83      0.87      0.85       172\n",
      "     Offensive_Targeted_Insult_Other       0.06      0.05      0.05        65\n",
      "     Offensive_Targeted_Insult_Group       0.28      0.54      0.37       295\n",
      "               Offensive_Untargetede       0.31      0.43      0.36       356\n",
      "Offensive_Targeted_Insult_Individual       0.36      0.40      0.38       307\n",
      "\n",
      "                            accuracy                           0.71      4388\n",
      "                           macro avg       0.46      0.51      0.48      4388\n",
      "                        weighted avg       0.77      0.71      0.73      4388\n",
      "\n",
      "XLMroberta_base_Tamil.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.88      0.90      0.89      3193\n",
      "                           not-Tamil       0.81      0.84      0.83       172\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
      "     Offensive_Targeted_Insult_Group       0.39      0.32      0.35       295\n",
      "               Offensive_Untargetede       0.42      0.48      0.45       356\n",
      "Offensive_Targeted_Insult_Individual       0.46      0.43      0.44       307\n",
      "\n",
      "                            accuracy                           0.78      4388\n",
      "                           macro avg       0.49      0.50      0.49      4388\n",
      "                        weighted avg       0.76      0.78      0.77      4388\n",
      "\n",
      "Indic_bert_Tamil.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.86      0.88      0.87      3193\n",
      "                           not-Tamil       0.80      0.74      0.77       172\n",
      "     Offensive_Targeted_Insult_Other       0.08      0.02      0.03        65\n",
      "     Offensive_Targeted_Insult_Group       0.26      0.29      0.28       295\n",
      "               Offensive_Untargetede       0.33      0.29      0.31       356\n",
      "Offensive_Targeted_Insult_Individual       0.32      0.36      0.34       307\n",
      "\n",
      "                            accuracy                           0.74      4388\n",
      "                           macro avg       0.44      0.43      0.43      4388\n",
      "                        weighted avg       0.73      0.74      0.73      4388\n",
      "\n",
      "MURIL_cased_temp_Tamil.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.86      0.90      0.88      3193\n",
      "                           not-Tamil       0.70      0.80      0.74       172\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
      "     Offensive_Targeted_Insult_Group       0.33      0.27      0.30       295\n",
      "               Offensive_Untargetede       0.40      0.46      0.43       356\n",
      "Offensive_Targeted_Insult_Individual       0.41      0.25      0.31       307\n",
      "\n",
      "                            accuracy                           0.76      4388\n",
      "                           macro avg       0.45      0.45      0.44      4388\n",
      "                        weighted avg       0.74      0.76      0.75      4388\n",
      "\n",
      "XLMroberta_from_custom_pretrained_Tamil.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.86      0.91      0.89      3193\n",
      "                           not-Tamil       0.87      0.76      0.81       172\n",
      "     Offensive_Targeted_Insult_Other       0.03      0.03      0.03        65\n",
      "     Offensive_Targeted_Insult_Group       0.39      0.31      0.35       295\n",
      "               Offensive_Untargetede       0.43      0.35      0.39       356\n",
      "Offensive_Targeted_Insult_Individual       0.46      0.41      0.44       307\n",
      "\n",
      "                            accuracy                           0.77      4388\n",
      "                           macro avg       0.51      0.46      0.48      4388\n",
      "                        weighted avg       0.76      0.77      0.76      4388\n",
      "\n",
      "XLMroberta_custom_pretrained_tamil_weighted.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.92      0.80      0.86      3193\n",
      "                           not-Tamil       0.82      0.85      0.83       172\n",
      "     Offensive_Targeted_Insult_Other       0.07      0.09      0.08        65\n",
      "     Offensive_Targeted_Insult_Group       0.31      0.47      0.37       295\n",
      "               Offensive_Untargetede       0.42      0.42      0.42       356\n",
      "Offensive_Targeted_Insult_Individual       0.33      0.58      0.42       307\n",
      "\n",
      "                            accuracy                           0.72      4388\n",
      "                           macro avg       0.48      0.54      0.50      4388\n",
      "                        weighted avg       0.78      0.72      0.75      4388\n",
      "\n",
      "Mbert_base_cased_tamil_weighted.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.91      0.80      0.85      3193\n",
      "                           not-Tamil       0.78      0.89      0.83       172\n",
      "     Offensive_Targeted_Insult_Other       0.06      0.17      0.09        65\n",
      "     Offensive_Targeted_Insult_Group       0.29      0.45      0.35       295\n",
      "               Offensive_Untargetede       0.32      0.31      0.32       356\n",
      "Offensive_Targeted_Insult_Individual       0.35      0.44      0.39       307\n",
      "\n",
      "                            accuracy                           0.71      4388\n",
      "                           macro avg       0.45      0.51      0.47      4388\n",
      "                        weighted avg       0.76      0.71      0.73      4388\n",
      "\n",
      "XLMroberta_custom_pretrained_Tamil_Weighted[0.01 1.   1.   1.   1.   1.  ].pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.96      0.60      0.74      3193\n",
      "                           not-Tamil       0.73      0.90      0.81       172\n",
      "     Offensive_Targeted_Insult_Other       0.04      0.09      0.05        65\n",
      "     Offensive_Targeted_Insult_Group       0.25      0.56      0.34       295\n",
      "               Offensive_Untargetede       0.24      0.56      0.34       356\n",
      "Offensive_Targeted_Insult_Individual       0.31      0.51      0.39       307\n",
      "\n",
      "                            accuracy                           0.60      4388\n",
      "                           macro avg       0.42      0.54      0.45      4388\n",
      "                        weighted avg       0.79      0.60      0.65      4388\n",
      "\n",
      "MURIL_cased_temp_tamil_weighted.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.87      0.84      0.85      3193\n",
      "                           not-Tamil       0.65      0.84      0.73       172\n",
      "     Offensive_Targeted_Insult_Other       0.01      0.02      0.01        65\n",
      "     Offensive_Targeted_Insult_Group       0.31      0.31      0.31       295\n",
      "               Offensive_Untargetede       0.35      0.31      0.33       356\n",
      "Offensive_Targeted_Insult_Individual       0.31      0.39      0.34       307\n",
      "\n",
      "                            accuracy                           0.71      4388\n",
      "                           macro avg       0.41      0.45      0.43      4388\n",
      "                        weighted avg       0.73      0.71      0.72      4388\n",
      "\n",
      "Indic_bert_tamil_weighted.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.88      0.78      0.83      3193\n",
      "                           not-Tamil       0.71      0.81      0.76       172\n",
      "     Offensive_Targeted_Insult_Other       0.08      0.03      0.04        65\n",
      "     Offensive_Targeted_Insult_Group       0.26      0.30      0.28       295\n",
      "               Offensive_Untargetede       0.26      0.46      0.34       356\n",
      "Offensive_Targeted_Insult_Individual       0.26      0.34      0.29       307\n",
      "\n",
      "                            accuracy                           0.68      4388\n",
      "                           macro avg       0.41      0.45      0.42      4388\n",
      "                        weighted avg       0.73      0.68      0.70      4388\n",
      "\n",
      "XLMroberta_base_tamil_weighted.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.91      0.80      0.85      3193\n",
      "                           not-Tamil       0.78      0.85      0.82       172\n",
      "     Offensive_Targeted_Insult_Other       0.04      0.09      0.06        65\n",
      "     Offensive_Targeted_Insult_Group       0.26      0.48      0.34       295\n",
      "               Offensive_Untargetede       0.42      0.33      0.37       356\n",
      "Offensive_Targeted_Insult_Individual       0.36      0.50      0.42       307\n",
      "\n",
      "                            accuracy                           0.71      4388\n",
      "                           macro avg       0.46      0.51      0.47      4388\n",
      "                        weighted avg       0.77      0.71      0.73      4388\n",
      "\n",
      "Mbert_base_cased_Tamil.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.84      0.94      0.88      3193\n",
      "                           not-Tamil       0.83      0.80      0.81       172\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
      "     Offensive_Targeted_Insult_Group       0.32      0.22      0.26       295\n",
      "               Offensive_Untargetede       0.36      0.40      0.38       356\n",
      "Offensive_Targeted_Insult_Individual       0.31      0.05      0.09       307\n",
      "\n",
      "                            accuracy                           0.76      4388\n",
      "                           macro avg       0.44      0.40      0.40      4388\n",
      "                        weighted avg       0.71      0.76      0.73      4388\n",
      "\n",
      "Distilbert_m_base_cased_tamil_weighted.pth.npy\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.89      0.80      0.84      3193\n",
      "                           not-Tamil       0.83      0.81      0.82       172\n",
      "     Offensive_Targeted_Insult_Other       0.03      0.03      0.03        65\n",
      "     Offensive_Targeted_Insult_Group       0.20      0.46      0.28       295\n",
      "               Offensive_Untargetede       0.33      0.25      0.29       356\n",
      "Offensive_Targeted_Insult_Individual       0.31      0.31      0.31       307\n",
      "\n",
      "                            accuracy                           0.69      4388\n",
      "                           macro avg       0.43      0.45      0.43      4388\n",
      "                        weighted avg       0.74      0.69      0.71      4388\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {\n",
    "    'Not_offensive': 0, \n",
    "    'not-Tamil': 1, \n",
    "    'Offensive_Targeted_Insult_Other': 2, \n",
    "    'Offensive_Targeted_Insult_Group': 3, \n",
    "    'Offensive_Untargetede': 4, \n",
    "    'Offensive_Targeted_Insult_Individual': 5\n",
    "}\n",
    "\n",
    "# Collecting Text and Labels\n",
    "train_batch_sentences = list(tamil_train['text'])\n",
    "train_batch_labels =  [label_mapping[x] for x in tamil_train['label']]\n",
    "dev_batch_sentences = list(tamil_dev['text'])\n",
    "dev_batch_labels =  [label_mapping[x] for x in tamil_dev['label']]\n",
    "\n",
    "for dev_preds, mn in zip(all_dev_preds, load_model_filenames):\n",
    "    final_dev_preds = np.argmax(dev_preds, axis = 1)\n",
    "    y_true = dev_batch_labels\n",
    "    y_pred = final_dev_preds\n",
    "    target_names = label_mapping.keys()\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names)\n",
    "    print(mn)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dev_preds = np.array(all_dev_preds)\n",
    "# Initialise Weights\n",
    "w = np.ones(all_dev_preds.shape[0])\n",
    "softmax_w = np.exp(w)/np.sum(np.exp(w))\n",
    "\n",
    "weighted_all_dev_preds = np.array([sw*dpreds for sw, dpreds in zip(softmax_w, all_dev_preds)])\n",
    "weighted_dev_preds = np.sum(weighted_all_dev_preds, axis = 0)\n",
    "final_dev_preds = np.argmax(weighted_dev_preds, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = dev_batch_labels\n",
    "y_pred = final_dev_preds\n",
    "target_names = label_mapping.keys()\n",
    "report = classification_report(y_true, y_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.89      0.91      0.90      3193\n",
      "                           not-Tamil       0.86      0.89      0.88       172\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
      "     Offensive_Targeted_Insult_Group       0.41      0.43      0.42       295\n",
      "               Offensive_Untargetede       0.48      0.46      0.47       356\n",
      "Offensive_Targeted_Insult_Individual       0.52      0.46      0.49       307\n",
      "\n",
      "                            accuracy                           0.80      4388\n",
      "                           macro avg       0.53      0.52      0.52      4388\n",
      "                        weighted avg       0.78      0.80      0.79      4388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising with GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The best solution found:                                                                           \n",
      " [3.50287451 3.42714936 4.61306262 3.75668652 3.35036097 2.54784582\n",
      " 3.61279716 4.14064798 4.05667854 1.64868604 2.0621329  3.18505631\n",
      " 3.16007808 3.52470656 4.30048129 2.23459362]\n",
      "\n",
      " Objective function:\n",
      " 0.20088652621660652\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "\n",
    "def f(X):\n",
    "    softmax_w = np.exp(X)/np.sum(np.exp(X))\n",
    "    weighted_all_dev_preds = np.array([sw*dpreds for sw, dpreds in zip(softmax_w, all_dev_preds)])\n",
    "    weighted_dev_preds = np.sum(weighted_all_dev_preds, axis = 0)\n",
    "    final_dev_preds = np.argmax(weighted_dev_preds, axis = 1)\n",
    "\n",
    "    y_true = dev_batch_labels\n",
    "    y_pred = final_dev_preds\n",
    "    score = f1_score(y_true, y_pred, average='weighted')\n",
    "    return 1-score\n",
    "\n",
    "varbound=np.array([[0, 5]]*all_dev_preds.shape[0])\n",
    "\n",
    "model=ga(function=f,dimension=all_dev_preds.shape[0],variable_type='real',variable_boundaries=varbound)\n",
    "\n",
    "model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence=model.report\n",
    "solution=model.output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variable': array([3.50287451, 3.42714936, 4.61306262, 3.75668652, 3.35036097,\n",
       "        2.54784582, 3.61279716, 4.14064798, 4.05667854, 1.64868604,\n",
       "        2.0621329 , 3.18505631, 3.16007808, 3.52470656, 4.30048129,\n",
       "        2.23459362]),\n",
       " 'function': 0.20088652621660652}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'solution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-58556f725262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'solution' is not defined"
     ]
    }
   ],
   "source": [
    "X = solution['variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "saved_model_filename = 'GA_tamil_v1'\n",
    "\n",
    "with open(\"../../dev_preds/weights_\" + saved_model_filename + \".pickle\", 'rb') as handle:\n",
    "    mw = pickle.load(handle)\n",
    "    \n",
    "X = [mw[index][0] for index in mw.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.502874513387141,\n",
       " 3.4271493615737363,\n",
       " 4.613062624093756,\n",
       " 3.756686520882169,\n",
       " 3.3503609716553395,\n",
       " 2.5478458171732794,\n",
       " 3.612797164824678,\n",
       " 4.140647982150272,\n",
       " 4.0566785354752835,\n",
       " 1.6486860434775181,\n",
       " 2.062132901324693,\n",
       " 3.1850563134890155,\n",
       " 3.1600780799724872,\n",
       " 3.5247065552175805,\n",
       " 4.3004812883262105,\n",
       " 2.2345936198354237]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_w = np.exp(X)/np.sum(np.exp(X))\n",
    "weighted_all_dev_preds = np.array([sw*dpreds for sw, dpreds in zip(softmax_w, all_dev_preds)])\n",
    "weighted_dev_preds = np.sum(weighted_all_dev_preds, axis = 0)\n",
    "final_dev_preds = np.argmax(weighted_dev_preds, axis = 1)\n",
    "\n",
    "y_true = dev_batch_labels\n",
    "y_pred = final_dev_preds\n",
    "target_names = label_mapping.keys()\n",
    "report = classification_report(y_true, y_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.88      0.93      0.91      3193\n",
      "                           not-Tamil       0.87      0.87      0.87       172\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
      "     Offensive_Targeted_Insult_Group       0.49      0.41      0.44       295\n",
      "               Offensive_Untargetede       0.50      0.47      0.49       356\n",
      "Offensive_Targeted_Insult_Individual       0.55      0.49      0.52       307\n",
      "\n",
      "                            accuracy                           0.81      4388\n",
      "                           macro avg       0.55      0.53      0.54      4388\n",
      "                        weighted avg       0.79      0.81      0.80      4388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5369532213406898"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saved_model_filename = 'GA_tamil_v1'\n",
    "np.savetxt(\"../../dev_preds/\" + saved_model_filename + \".csv\", final_dev_preds, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../../model_prediction_probs/\"+saved_model_filename+\".npy\", weighted_dev_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {x:(y,z) for x, y, z in zip(load_model_filenames, np.array(solution['variable']), model_pretrained_keys)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../../dev_preds/weights_\" + saved_model_filename + \".pickle\", 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nlp]",
   "language": "python",
   "name": "conda-env-.conda-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
