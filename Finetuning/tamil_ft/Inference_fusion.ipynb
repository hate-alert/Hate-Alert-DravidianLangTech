{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV from link\n",
    "def read_csv_from_link(url):\n",
    "    path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "    df = pd.read_csv(path,delimiter=\"\\t\",error_bad_lines=False, header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2399: expected 2 fields, saw 3\\nSkipping line 2525: expected 2 fields, saw 3\\n'\n",
      "b'Skipping line 777: expected 2 fields, saw 3\\n'\n"
     ]
    }
   ],
   "source": [
    "# Loading All Data\n",
    "tamil_train = read_csv_from_link('https://drive.google.com/file/d/15auwrFAlq52JJ61u7eSfnhT9rZtI5sjk/view?usp=sharing')\n",
    "tamil_dev = read_csv_from_link('https://drive.google.com/file/d/1Jme-Oftjm7OgfMNLKQs1mO_cnsQmznRI/view?usp=sharing')\n",
    "mal_train = read_csv_from_link('https://drive.google.com/file/d/13JCCr-IjZK7uhbLXeufptr_AxvsKinVl/view?usp=sharing')\n",
    "mal_dev = read_csv_from_link('https://drive.google.com/file/d/1J0msLpLoM6gmXkjC6DFeQ8CG_rrLvjnM/view?usp=sharing')\n",
    "kannada_train = read_csv_from_link('https://drive.google.com/file/d/1XuOhSpdK8qsbO-lZHrIcVaU5FsCXc05T/view?usp=sharing')\n",
    "kannada_dev = read_csv_from_link('https://drive.google.com/file/d/164zYZOeXIwt5jl3NggJU0CWRyD2fRT9z/view?usp=sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamil Preprocess\n",
    "tamil_train = tamil_train.iloc[:, 0:2]\n",
    "tamil_train = tamil_train.rename(columns={0: \"text\", 1: \"label\"})\n",
    "\n",
    "tamil_dev = tamil_dev.iloc[:, 0:2]\n",
    "tamil_dev = tamil_dev.rename(columns={0: \"text\", 1: \"label\"})\n",
    "\n",
    "# Stats\n",
    "tamil_train['label'] = pd.Categorical(tamil_train.label)\n",
    "tamil_dev['label'] = pd.Categorical(tamil_dev.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Nos: 2\n",
      "Tesla P100-PCIE-12GB\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Nos: {}\".format(torch.cuda.device_count()))\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_name(1))\n",
    "\n",
    "# Change Device - CPU/GPU-0/GPU-1\n",
    "torch.cuda.set_device(1)\n",
    "device = 'cuda'\n",
    "device = device if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter Path of Saved model here in torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Select\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "file_list = listdir('../finetuned_models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_filename = 'fusion_v1.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "tokenizers = []\n",
    "\n",
    "# Loading Model\n",
    "saved_model_filename = 'Mbert_base_cased_Tamil.pth'\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "load_dict = torch.load(os.path.join('../finetuned_models/', saved_model_filename))\n",
    "load_dict = {k.split('bert.')[-1]: v for k, v in load_dict.items()}\n",
    "load_dict = {k: v for k, v in load_dict.items() if k in model.state_dict()}\n",
    "model.load_state_dict(load_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "models.append(model)\n",
    "tokenizers.append(tokenizer)\n",
    "\n",
    "# Loading Model\n",
    "saved_model_filename = 'XLMroberta_from_custom_pretrained_Tamil.pth'\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, XLMRobertaModel\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "model = XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "load_dict = torch.load(os.path.join('../finetuned_models/', saved_model_filename))\n",
    "load_dict = {k.split('roberta.')[-1]: v for k, v in load_dict.items()}\n",
    "load_dict = {k: v for k, v in load_dict.items() if k in model.state_dict()}\n",
    "model.load_state_dict(load_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "models.append(model)\n",
    "tokenizers.append(tokenizer)\n",
    "\n",
    "# Using Indic Bert\n",
    "saved_model_filename = 'Indic_bert_Tamil.pth'\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "model = AutoModel.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "\n",
    "load_dict = torch.load(os.path.join('../finetuned_models/', saved_model_filename))\n",
    "load_dict = {k.split('albert.')[-1]: v for k, v in load_dict.items()}\n",
    "load_dict = {k: v for k, v in load_dict.items() if k in model.state_dict()}\n",
    "model.load_state_dict(load_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "models.append(model)\n",
    "tokenizers.append(tokenizer)\n",
    "\n",
    "n_models = len(models)\n",
    "\n",
    "for model in models:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'Not_offensive': 0, \n",
    "    'not-Tamil': 1, \n",
    "    'Offensive_Targeted_Insult_Other': 2, \n",
    "    'Offensive_Targeted_Insult_Group': 3, \n",
    "    'Offensive_Untargetede': 4, \n",
    "    'Offensive_Targeted_Insult_Individual': 5\n",
    "}\n",
    "\n",
    "# Collecting Text and Labels\n",
    "train_batch_sentences = list(tamil_train['text'])\n",
    "train_batch_labels =  [label_mapping[x] for x in tamil_train['label']]\n",
    "dev_batch_sentences = list(tamil_dev['text'])\n",
    "dev_batch_labels =  [label_mapping[x] for x in tamil_dev['label']]\n",
    "\n",
    "# Convert to Tensor\n",
    "train_encodings = [tokenizer(train_batch_sentences, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\") for tokenizer in tokenizers]\n",
    "train_labels = torch.tensor(train_batch_labels)\n",
    "dev_encodings = [tokenizer(dev_batch_sentences, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\") for tokenizer in tokenizers]\n",
    "dev_labels = torch.tensor(dev_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Tamil_Offensive_Dataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.n_models = len(encodings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        for i in range(self.n_models):\n",
    "            item.update({key+'_'+str(i): torch.tensor(val[idx]) for key, val in self.encodings[i].items()})\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Defining Datasets\n",
    "dev_dataset = Tamil_Offensive_Dataset(dev_encodings, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# Basic Fully-Connected (Linear => BatchNorm => ReLU)\n",
    "class BasicFC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicFC, self).__init__()\n",
    "        self.fc = nn.Linear(in_channels, out_channels, **kwargs)\n",
    "        self.bn = nn.BatchNorm1d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "class FusionNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(FusionNet, self).__init__()\n",
    "        self.linear1_1 = BasicFC(D_in, H1)\n",
    "        self.linear1_2 = BasicFC(H1, H2)\n",
    "        self.dp = nn.Dropout(0.1)\n",
    "        self.linear2 = torch.nn.Linear(H2, D_out, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_relu_1 = self.linear1_1(x)\n",
    "        h_relu_2 = self.dp(self.linear1_2(h_relu_1))\n",
    "        y_pred = self.linear2(h_relu_2)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec60cbe400c47bdbbb7da1ce2fa10e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=275.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "fusion_classifier = FusionNet(2304, 256, 64, 6)\n",
    "fusion_classifier.load_state_dict(torch.load(os.path.join('../finetuned_models/', saved_model_filename)))\n",
    "fusion_classifier.eval()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "fusion_classifier.to(device)\n",
    "for model in models:\n",
    "    model.to(device)\n",
    "\n",
    "# Dataloaders\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "dev_preds = []\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch in tqdm(dev_loader):\n",
    "        outputs_all = []\n",
    "        for i in range(n_models):\n",
    "            model = models[i]\n",
    "            input_ids = batch['input_ids'+'_'+str(i)].to(device)\n",
    "            attention_mask = batch['attention_mask'+'_'+str(i)].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            outputs_all.append(outputs[1])\n",
    "\n",
    "        bert_output = torch.cat(outputs_all, dim = -1) \n",
    "        out = fusion_classifier(bert_output)\n",
    "\n",
    "        for logits in out.cpu().numpy():\n",
    "            dev_preds.append(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = dev_batch_labels\n",
    "y_pred = dev_preds\n",
    "target_names = label_mapping.keys()\n",
    "report = classification_report(y_true, y_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../dev_preds/\" + saved_model_filename[:-4] + \".csv\", dev_preds, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.88      0.90      0.89      3193\n",
      "                           not-Tamil       0.87      0.84      0.86       172\n",
      "     Offensive_Targeted_Insult_Other       0.04      0.05      0.04        65\n",
      "     Offensive_Targeted_Insult_Group       0.39      0.37      0.38       295\n",
      "               Offensive_Untargetede       0.45      0.39      0.42       356\n",
      "Offensive_Targeted_Insult_Individual       0.47      0.44      0.45       307\n",
      "\n",
      "                            accuracy                           0.78      4388\n",
      "                           macro avg       0.52      0.50      0.51      4388\n",
      "                        weighted avg       0.77      0.78      0.77      4388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nlp]",
   "language": "python",
   "name": "conda-env-.conda-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
